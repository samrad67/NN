# ----------------------------
# MNIST CNN (corrected + commented)
# ----------------------------

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import torchvision
import torchvision.transforms as transforms


# ----------------------------
# 1) Device (CPU / GPU)
# ----------------------------
# If you have an NVIDIA GPU + CUDA installed, this will use it.
# Otherwise it will fall back to CPU.
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)


# ----------------------------
# 2) Data transforms + dataset
# ----------------------------
# MNIST is GRAYSCALE (1 channel), so Normalize must be 1 value, not (0.5,0.5,0.5).
# ToTensor() gives values in [0, 1].
# Normalize((0.5,), (0.5,)) maps [0,1] -> [-1, +1].
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

trainset = torchvision.datasets.MNIST(
    root="mnist",
    train=True,
    download=True,
    transform=transform
)

testset = torchvision.datasets.MNIST(
    root="mnist",
    train=False,
    download=True,
    transform=transform
)

# DataLoaders: batch_size=128 is fine for MNIST
trainloader = torch.utils.data.DataLoader(
    trainset,
    batch_size=128,
    shuffle=True,
    num_workers=0
)

testloader = torch.utils.data.DataLoader(
    testset,
    batch_size=128,
    shuffle=False,
    num_workers=0
)


# ----------------------------
# 3) Model definition
# ----------------------------
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()

        # Input: (N, 1, 28, 28)
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)
        # After conv1 (no padding, stride 1): (N, 32, 26, 26)

        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)
        # After conv2: (N, 64, 24, 24)

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        # After pool: (N, 64, 12, 12)

        # Flatten size = 64 * 12 * 12 = 9216
        self.fc1 = nn.Linear(64 * 12 * 12, 128)
        self.fc2 = nn.Linear(128, 10)  # 10 classes (digits 0..9)

    def forward(self, x):
        # Conv -> ReLU
        x = F.relu(self.conv1(x))
        # Conv -> ReLU -> Pool
        x = self.pool(F.relu(self.conv2(x)))

        # Flatten: keep batch dimension, flatten the rest
        x = x.view(x.size(0), 64 * 12 * 12)

        # Fully connected layers
        x = F.relu(self.fc1(x))
        x = self.fc2(x)  # raw logits (NO softmax needed for CrossEntropyLoss)
        return x


net = Net().to(device)


# ----------------------------
# 4) Loss + Optimizer
# ----------------------------
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)


# ----------------------------
# 5) Evaluation helper
# ----------------------------
def evaluate_accuracy(model, loader, device):
    # Important: eval mode disables training behaviors (dropout/bn if you add later)
    model.eval()

    correct = 0
    total = 0

    # No gradients needed for evaluation
    with torch.no_grad():
        for images, labels in loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)              # logits
            _, predicted = torch.max(outputs, 1) # class index

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    acc = 100.0 * correct / total
    return acc


# ----------------------------
# 6) Training loop
# ----------------------------
epochs = 10

epoch_log = []
loss_log = []
accuracy_log = []

for epoch in range(epochs):
    print(f"\nStarting Epoch: {epoch + 1}/{epochs}")

    # Training mode (important if you add dropout/bn later)
    net.train()

    running_loss = 0.0
    log_every = 50  # mini-batches

    for i, (inputs, labels) in enumerate(trainloader, start=1):
        inputs = inputs.to(device)
        labels = labels.to(device)

        # Clear old gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = net(inputs)

        # Compute loss
        loss = criterion(outputs, labels)

        # Backprop (compute gradients)
        loss.backward()

        # Update weights
        optimizer.step()

        # Accumulate loss for logging
        running_loss += loss.item()

        # Log every N mini-batches
        if i % log_every == 0:
            # Average loss over the last log_every batches
            avg_loss = running_loss / log_every

            # Evaluate on test set
            test_acc = evaluate_accuracy(net, testloader, device)

            print(f"Epoch {epoch + 1}, Mini-batches {i}, Loss: {avg_loss:.3f}, Test Accuracy: {test_acc:.2f}%")

            # Reset running loss
            running_loss = 0.0

            # Save logs (optional)
            epoch_log.append(epoch + 1)
            loss_log.append(avg_loss)
            accuracy_log.append(test_acc)

print("\nFinished Training")
final_acc = evaluate_accuracy(net, testloader, device)
print(f"Final Test Accuracy: {final_acc:.2f}%")
torch.save(net.state_dict(), "mnist_cnn.pth")
print("Model saved as mnist_cnn.pth")
